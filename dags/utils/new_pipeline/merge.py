import pandas as pd
import asyncio
from concurrent.futures import ThreadPoolExecutor
import logging
import time
from typing import List, Callable, Tuple, Optional
import sys
import traceback

# Import your scraper functions
from utils.new_pipeline.vietstock_ngay import vietstock
from utils.new_pipeline.tinnhanh_ngay import tinnhanh  
from utils.new_pipeline.cafeF_ngay import cafef

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
)
log = logging.getLogger(__name__)

def safe_scraper_wrapper(scraper_func: Callable) -> pd.DataFrame:
    """
    Wrapper function Ä‘á»ƒ báº¯t lá»—i vÃ  Ä‘áº£m báº£o return DataFrame
    """
    start_time = time.time()
    try:
        log.info(f"ğŸš€ Báº¯t Ä‘áº§u {scraper_func.__name__}")
        result = scraper_func()
        
        if isinstance(result, pd.DataFrame):
            if not result.empty:
                execution_time = round(time.time() - start_time, 2)
                log.info(f"âœ… {scraper_func.__name__}: {len(result)} bÃ i viáº¿t trong {execution_time}s")
                return result
            else:
                log.warning(f"âš ï¸ {scraper_func.__name__}: DataFrame trá»‘ng")
                return pd.DataFrame()
        else:
            log.error(f"âŒ {scraper_func.__name__}: KhÃ´ng tráº£ vá» DataFrame")
            return pd.DataFrame()
            
    except Exception as e:
        execution_time = round(time.time() - start_time, 2)
        log.error(f"âŒ {scraper_func.__name__} lá»—i sau {execution_time}s: {e}")
        log.error(f"Chi tiáº¿t lá»—i: {traceback.format_exc()}")
        return pd.DataFrame()

async def run_in_thread(func: Callable, executor: ThreadPoolExecutor) -> pd.DataFrame:
    """
    Cháº¡y scraper function trong thread pool
    """
    loop = asyncio.get_running_loop()
    try:
        result = await loop.run_in_executor(executor, safe_scraper_wrapper, func)
        return result
    except Exception as e:
        log.error(f"âŒ Thread execution error cho {func.__name__}: {e}")
        return pd.DataFrame()

async def tintuc_async() -> Tuple[pd.DataFrame, dict]:
    """
    Cháº¡y táº¥t cáº£ scrapers async vá»›i error handling vÃ  stats
    """
    log.info("ğŸ¯ Báº¯t Ä‘áº§u async news scraping pipeline")
    
    # Äá»‹nh nghÄ©a scrapers
    scrapers = [
        (vietstock, "VietStock"),
        (tinnhanh, "TinNhanh"),
        (cafef, "CafeF")
    ]
    
    results = []
    stats = {}
    start_time = time.time()
    
    # Sá»­ dá»¥ng ThreadPoolExecutor vá»›i max_workers phÃ¹ há»£p
    max_workers = min(len(scrapers), 3)  # KhÃ´ng quÃ¡ 3 workers
    
    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Táº¡o tasks
            tasks = []
            for scraper_func, scraper_name in scrapers:
                task = run_in_thread(scraper_func, executor)
                tasks.append((task, scraper_name))
            
            # Cháº¡y táº¥t cáº£ tasks
            log.info(f"âš¡ Cháº¡y {len(tasks)} scrapers song song...")
            
            # Gather vá»›i timeout
            try:
                task_results = await asyncio.wait_for(
                    asyncio.gather(*[task for task, _ in tasks], return_exceptions=True),
                    timeout=300  # 5 phÃºt timeout
                )
            except asyncio.TimeoutError:
                log.error("âŒ Async tasks timeout sau 5 phÃºt")
                task_results = [pd.DataFrame() for _ in tasks]
            
            # Process results
            for (task, scraper_name), result in zip(tasks, task_results):
                if isinstance(result, Exception):
                    log.error(f"âŒ {scraper_name}: Exception - {result}")
                    stats[scraper_name] = {
                        'status': 'error',
                        'articles': 0,
                        'error': str(result)
                    }
                elif isinstance(result, pd.DataFrame):
                    if not result.empty:
                        results.append(result)
                        stats[scraper_name] = {
                            'status': 'success', 
                            'articles': len(result)
                        }
                        log.info(f"âœ… {scraper_name}: {len(result)} bÃ i viáº¿t")
                    else:
                        stats[scraper_name] = {
                            'status': 'no_data',
                            'articles': 0
                        }
                        log.warning(f"âš ï¸ {scraper_name}: KhÃ´ng cÃ³ dá»¯ liá»‡u")
                else:
                    log.error(f"âŒ {scraper_name}: Unexpected result type - {type(result)}")
                    stats[scraper_name] = {
                        'status': 'error',
                        'articles': 0,
                        'error': f'Unexpected result type: {type(result)}'
                    }
    
    except Exception as e:
        log.error(f"âŒ Lá»—i trong ThreadPoolExecutor: {e}")
        for _, scraper_name in scrapers:
            if scraper_name not in stats:
                stats[scraper_name] = {
                    'status': 'error',
                    'articles': 0,
                    'error': str(e)
                }
    
    # Combine results
    total_time = round(time.time() - start_time, 2)
    
    if results:
        try:
            df_all = pd.concat(results, ignore_index=True)
            
            # Remove duplicates if any
            initial_count = len(df_all)
            if 'Link' in df_all.columns:
                df_all = df_all.drop_duplicates(subset=['Link'], keep='first')
                final_count = len(df_all)
                if initial_count != final_count:
                    log.info(f"ğŸ”„ Removed {initial_count - final_count} duplicates")
            
            log.info(f"ğŸ‰ Pipeline hoÃ n thÃ nh: {len(df_all)} bÃ i viáº¿t trong {total_time}s")
            
            # Print detailed stats
            log.info("ğŸ“Š Chi tiáº¿t káº¿t quáº£:")
            total_articles = 0
            successful_scrapers = 0
            
            for scraper_name, stat in stats.items():
                status = stat['status']
                articles = stat['articles']
                
                if status == 'success':
                    log.info(f"   âœ… {scraper_name}: {articles} bÃ i viáº¿t")
                    total_articles += articles
                    successful_scrapers += 1
                elif status == 'no_data':
                    log.info(f"   âš ï¸ {scraper_name}: KhÃ´ng cÃ³ dá»¯ liá»‡u")
                else:
                    error = stat.get('error', 'Unknown error')
                    log.info(f"   âŒ {scraper_name}: Lá»—i - {error}")
            
            stats['summary'] = {
                'total_articles': len(df_all),
                'total_time': total_time,
                'successful_scrapers': successful_scrapers,
                'total_scrapers': len(scrapers)
            }
            
            return df_all, stats
            
        except Exception as e:
            log.error(f"âŒ Lá»—i khi concat DataFrames: {e}")
            return pd.DataFrame(), stats
    else:
        log.error(f"âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u sau {total_time}s")
        stats['summary'] = {
            'total_articles': 0,
            'total_time': total_time,
            'successful_scrapers': 0,
            'total_scrapers': len(scrapers)
        }
        return pd.DataFrame(), stats

def tintuc() -> pd.DataFrame:
    """
    Wrapper Ä‘á»“ng bá»™ Ä‘á»ƒ gá»i tá»« Airflow tasks
    """
    try:
        # Kiá»ƒm tra event loop
        try:
            loop = asyncio.get_running_loop()
            log.warning("âš ï¸ Event loop Ä‘Ã£ tá»“n táº¡i, táº¡o new event loop")
            # Náº¿u Ä‘Ã£ cÃ³ loop, táº¡o loop má»›i trong thread
            import threading
            result = []
            exception = []
            
            def run_in_new_thread():
                try:
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    df, stats = new_loop.run_until_complete(tintuc_async())
                    result.append(df)
                except Exception as e:
                    exception.append(e)
                finally:
                    new_loop.close()
            
            thread = threading.Thread(target=run_in_new_thread)
            thread.start()
            thread.join(timeout=400)  # 6 phÃºt 40 giÃ¢y timeout
            
            if thread.is_alive():
                log.error("âŒ Thread timeout")
                return pd.DataFrame()
            
            if exception:
                raise exception[0]
            
            return result[0] if result else pd.DataFrame()
            
        except RuntimeError:
            # KhÃ´ng cÃ³ event loop, cháº¡y bÃ¬nh thÆ°á»ng
            df, stats = asyncio.run(tintuc_async())
            return df
            
    except Exception as e:
        log.error(f"âŒ Lá»—i trong tintuc(): {e}")
        log.error(f"Chi tiáº¿t lá»—i: {traceback.format_exc()}")
        return pd.DataFrame()

async def main():
    """
    Function Ä‘á»ƒ test async pipeline
    """
    df, stats = await tintuc_async()
    print(f"\nğŸ¯ Káº¿t quáº£: {len(df)} bÃ i viáº¿t")
    print(f"ğŸ“Š Stats: {stats}")
    
    if not df.empty:
        print(f"\nğŸ“ Sample data:")
        print(df.head())
        print(f"\nğŸ“‹ Columns: {df.columns.tolist()}")
    
    return df, stats

