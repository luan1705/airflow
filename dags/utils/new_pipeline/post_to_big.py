from sqlalchemy import create_engine
import pandas as pd
from google.cloud import bigquery
import logging

def add_bigquery():
    log = logging.getLogger(__name__)

    try:
        # Káº¿t ná»‘i PostgreSQL
        engine = create_engine('postgresql://vnsfintech:%40Vns123456@videv.cloud:5432/vnsfintech')
        log.info("âœ… Káº¿t ná»‘i PostgreSQL thÃ nh cÃ´ng.")

        # Äá»c dá»¯ liá»‡u tá»« báº£ng News
        df = pd.read_sql('SELECT * FROM "news"."News"', con=engine)
        if df.empty:
            log.info("ğŸ“­ Báº£ng News rá»—ng, khÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ upload lÃªn BigQuery.")
            return "KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ Ä‘áº©y lÃªn BigQuery"

        # Káº¿t ná»‘i BigQuery báº±ng service account
        client = bigquery.Client.from_service_account_json('/opt/bigquerrykey/nodal-spot-461206-d5-c9606b21be08.json')

        table_id = 'nodal-spot-461206-d5.News_data.News'  # format: project.dataset.table

        # Cáº¥u hÃ¬nh ghi Ä‘Ã¨ (náº¿u cÃ³ báº£ng cÅ©)
        job_config = bigquery.LoadJobConfig(write_disposition="WRITE_TRUNCATE")

        # Táº£i lÃªn BigQuery
        load_job = client.load_table_from_dataframe(df, table_id, job_config=job_config)
        load_job.result()  # Chá» upload xong

        log.info(f"âœ… ÄÃ£ upload {len(df)} dÃ²ng lÃªn BigQuery table {table_id}.")

        return f"ÄÃ£ upload {len(df)} dÃ²ng lÃªn BigQuery"

    except Exception as e:
        log.error(f"âŒ Lá»—i khi Ä‘áº©y dá»¯ liá»‡u lÃªn BigQuery: {e}")
        raise
